# -*- coding: utf-8 -*-
"""
RSS é˜…è¯»å™¨ - Python å­¦ä¹ ç»ƒä¹ 
åŸºäºåŸé¡¹ç›®çš„æ‰©å±•ç»ƒä¹ ï¼Œå¸®åŠ©æŒæ¡ Python æ ¸å¿ƒæ¦‚å¿µ
"""

import json
import requests
import feedparser
from datetime import datetime
from typing import List, Dict
import re

class RSSReaderLearning:
    """
    æ‰©å±•ç»ƒä¹ ç‰ˆæœ¬çš„ RSS é˜…è¯»å™¨
    ç”¨äºå­¦ä¹  Python ç¼–ç¨‹æ¦‚å¿µ
    """
    
    def __init__(self):
        self.config_file = "rss_subscriptions.json"
        self.favorites_file = "rss_favorites.json"
        self.history_file = "search_history.json"
        
        self.subscriptions = {}
        self.favorites = []
        self.search_history = []
        
        self.load_subscriptions()
        self.load_favorites()
        self.load_search_history()
    
    # ç»ƒä¹ 1ï¼šæ·»åŠ æ”¶è—åŠŸèƒ½
    def add_to_favorites(self, article: Dict) -> bool:
        """
        å­¦ä¹ è¦ç‚¹ï¼š
        - å­—å…¸æ“ä½œå’Œåˆ—è¡¨æ“ä½œ
        - æ•°æ®å»é‡é€»è¾‘
        - æ–‡ä»¶æŒä¹…åŒ–
        """
        try:
            # æ£€æŸ¥æ˜¯å¦å·²æ”¶è—
            for fav in self.favorites:
                if fav['link'] == article['link']:
                    print("âš ï¸  æ–‡ç« å·²åœ¨æ”¶è—å¤¹ä¸­")
                    return False
            
            # æ·»åŠ æ”¶è—æ—¶é—´
            article['favorited_at'] = datetime.now().isoformat()
            self.favorites.append(article)
            self.save_favorites()
            print("â­ æ–‡ç« å·²æ·»åŠ åˆ°æ”¶è—å¤¹")
            return True
            
        except Exception as e:
            print(f"âŒ æ”¶è—å¤±è´¥: {e}")
            return False
    
    def save_favorites(self):
        """ä¿å­˜æ”¶è—åˆ°æ–‡ä»¶"""
        try:
            with open(self.favorites_file, 'w', encoding='utf-8') as f:
                json.dump(self.favorites, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸  æ”¶è—ä¿å­˜å¤±è´¥: {e}")
    
    def load_favorites(self):
        """ä»æ–‡ä»¶åŠ è½½æ”¶è—"""
        try:
            with open(self.favorites_file, 'r', encoding='utf-8') as f:
                self.favorites = json.load(f)
        except FileNotFoundError:
            self.favorites = []
        except Exception as e:
            print(f"âš ï¸  æ”¶è—åŠ è½½å¤±è´¥: {e}")
            self.favorites = []
    
    # ç»ƒä¹ 2ï¼šæœç´¢å†å²åŠŸèƒ½
    def add_to_search_history(self, keyword: str):
        """
        å­¦ä¹ è¦ç‚¹ï¼š
        - åˆ—è¡¨æ“ä½œï¼ˆå»é‡ã€é™åˆ¶é•¿åº¦ï¼‰
        - æ•°æ®ç»“æ„è®¾è®¡
        """
        try:
            # å¦‚æœå…³é”®è¯å·²å­˜åœ¨ï¼Œå…ˆç§»é™¤
            if keyword in self.search_history:
                self.search_history.remove(keyword)
            
            # æ·»åŠ åˆ°å¼€å¤´
            self.search_history.insert(0, keyword)
            
            # é™åˆ¶å†å²è®°å½•æ•°é‡
            if len(self.search_history) > 10:
                self.search_history = self.search_history[:10]
            
            self.save_search_history()
            
        except Exception as e:
            print(f"âš ï¸  æœç´¢å†å²ä¿å­˜å¤±è´¥: {e}")
    
    def save_search_history(self):
        """ä¿å­˜æœç´¢å†å²"""
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(self.search_history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸  æœç´¢å†å²ä¿å­˜å¤±è´¥: {e}")
    
    def load_search_history(self):
        """åŠ è½½æœç´¢å†å²"""
        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                self.search_history = json.load(f)
        except FileNotFoundError:
            self.search_history = []
        except Exception as e:
            print(f"âš ï¸  æœç´¢å†å²åŠ è½½å¤±è´¥: {e}")
            self.search_history = []
    
    # ç»ƒä¹ 3ï¼šæ–‡ç« ç»Ÿè®¡åŠŸèƒ½
    def get_statistics(self) -> Dict:
        """
        å­¦ä¹ è¦ç‚¹ï¼š
        - æ•°æ®ç»Ÿè®¡å’Œè®¡ç®—
        - å­—å…¸æ“ä½œ
        - åˆ—è¡¨æ¨å¯¼å¼
        """
        stats = {
            'total_subscriptions': len(self.subscriptions),
            'total_favorites': len(self.favorites),
            'recent_searches': len(self.search_history)
        }
        
        # ç»Ÿè®¡æ”¶è—æ–‡ç« çš„æ¥æºåˆ†å¸ƒï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if self.favorites:
            sources = {}
            for article in self.favorites:
                # ä»é“¾æ¥æå–åŸŸå
                domain = self.extract_domain(article.get('link', ''))
                sources[domain] = sources.get(domain, 0) + 1
            stats['favorite_sources'] = sources
        
        return stats
    
    def extract_domain(self, url: str) -> str:
        """
        å­¦ä¹ è¦ç‚¹ï¼š
        - æ­£åˆ™è¡¨è¾¾å¼
        - å­—ç¬¦ä¸²å¤„ç†
        """
        try:
            import re
            pattern = r'https?://([^/]+)'
            match = re.search(pattern, url)
            return match.group(1) if match else 'unknown'
        except:
            return 'unknown'
    
    # ç»ƒä¹ 4ï¼šé«˜çº§æœç´¢åŠŸèƒ½
    def advanced_search(self, articles: List[Dict], **kwargs) -> List[Dict]:
        """
        å­¦ä¹ è¦ç‚¹ï¼š
        - **kwargs å¯å˜å…³é”®å­—å‚æ•°
        - å¤åˆæ¡ä»¶ç­›é€‰
        - æ—¥æœŸå¤„ç†
        """
        filtered = articles[:]
        
        # æ ‡é¢˜å…³é”®è¯æœç´¢
        if 'title_keyword' in kwargs:
            keyword = kwargs['title_keyword'].lower()
            filtered = [a for a in filtered if keyword in a['title'].lower()]
        
        # æ‘˜è¦å…³é”®è¯æœç´¢
        if 'summary_keyword' in kwargs:
            keyword = kwargs['summary_keyword'].lower()
            filtered = [a for a in filtered if keyword in a['summary'].lower()]
        
        # æ—¥æœŸèŒƒå›´æœç´¢ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
        if 'date_from' in kwargs:
            # å®é™…åº”ç”¨ä¸­éœ€è¦è§£ææ—¥æœŸå­—ç¬¦ä¸²
            pass
        
        return filtered
    
    # ç»ƒä¹ 5ï¼šæ–‡ç« å¯¼å‡ºåŠŸèƒ½
    def export_articles(self, articles: List[Dict], format: str = 'markdown') -> str:
        """
        å­¦ä¹ è¦ç‚¹ï¼š
        - æ–‡ä»¶æ ¼å¼å¤„ç†
        - å­—ç¬¦ä¸²æ¨¡æ¿
        - æ¡ä»¶åˆ†æ”¯
        """
        if format.lower() == 'markdown':
            return self.export_to_markdown(articles)
        elif format.lower() == 'html':
            return self.export_to_html(articles)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")
    
    def export_to_markdown(self, articles: List[Dict]) -> str:
        """å¯¼å‡ºä¸º Markdown æ ¼å¼"""
        md_content = "# RSS æ–‡ç« å¯¼å‡º\n\n"
        md_content += f"å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        
        for i, article in enumerate(articles, 1):
            md_content += f"## {i}. {article['title']}\n\n"
            md_content += f"**é“¾æ¥**: {article['link']}\n\n"
            md_content += f"**å‘å¸ƒæ—¶é—´**: {article.get('published', 'æœªçŸ¥')}\n\n"
            md_content += f"**æ‘˜è¦**: {article.get('summary', 'æ— æ‘˜è¦')}\n\n"
            md_content += "---\n\n"
        
        return md_content
    
    def export_to_html(self, articles: List[Dict]) -> str:
        """å¯¼å‡ºä¸º HTML æ ¼å¼"""
        html_content = """
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <title>RSS æ–‡ç« å¯¼å‡º</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 20px; }
                .article { border-bottom: 1px solid #ccc; padding: 20px 0; }
                .title { color: #333; font-size: 18px; font-weight: bold; }
                .link { color: #0066cc; }
                .date { color: #666; font-size: 14px; }
                .summary { margin-top: 10px; }
            </style>
        </head>
        <body>
            <h1>RSS æ–‡ç« å¯¼å‡º</h1>
        """
        
        for article in articles:
            html_content += f"""
            <div class="article">
                <div class="title">{article['title']}</div>
                <div class="date">å‘å¸ƒæ—¶é—´: {article.get('published', 'æœªçŸ¥')}</div>
                <div class="link"><a href="{article['link']}" target="_blank">æŸ¥çœ‹åŸæ–‡</a></div>
                <div class="summary">{article.get('summary', 'æ— æ‘˜è¦')}</div>
            </div>
            """
        
        html_content += """
        </body>
        </html>
        """
        
        return html_content
    
    # ä»åŸé¡¹ç›®ç»§æ‰¿çš„åŸºç¡€æ–¹æ³•
    def load_subscriptions(self):
        """åŠ è½½è®¢é˜…æº"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.subscriptions = json.load(f)
        except FileNotFoundError:
            self.subscriptions = {}
        except Exception as e:
            print(f"âš ï¸  é…ç½®åŠ è½½å¤±è´¥: {e}")
            self.subscriptions = {}


def main():
    """
    ä¸»å‡½æ•° - æ¼”ç¤ºå„ç§åŠŸèƒ½
    å­¦ä¹ è¦ç‚¹ï¼š
    - ç¨‹åºå…¥å£ç‚¹è®¾è®¡
    - ç”¨æˆ·äº¤äº’æµç¨‹
    """
    reader = RSSReaderLearning()
    
    print("ğŸ“ RSS é˜…è¯»å™¨ - Python å­¦ä¹ ç‰ˆ")
    print("=" * 40)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = reader.get_statistics()
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   è®¢é˜…æºæ•°é‡: {stats['total_subscriptions']}")
    print(f"   æ”¶è—æ–‡ç« : {stats['total_favorites']}")
    print(f"   æœç´¢å†å²: {stats['recent_searches']}")
    
    # æ˜¾ç¤ºæœç´¢å†å²
    if reader.search_history:
        print(f"\nğŸ” æœ€è¿‘æœç´¢: {', '.join(reader.search_history[:5])}")


if __name__ == "__main__":
    main()
