# 网络编程与第三方库使用

## 📚 本文档目标

深入学习 RSS 项目中的网络编程和第三方库使用，理解如何与外部服务交互并处理数据。通过本文档，你将：

- 掌握 HTTP 请求的基本原理
- 熟练使用 `requests` 库发送网络请求
- 理解 `feedparser` 库的 RSS/Atom 解析机制
- 学习处理网络请求中的异常和错误
- 掌握依赖管理和虚拟环境的最佳实践

## 🌐 HTTP 请求基础

### 1. HTTP 请求与响应

在 RSS 项目中，程序通过发送 HTTP GET 请求到 RSS 源的 URL 来获取数据。

**HTTP 请求的关键组成部分**：
- **请求方法**：`GET`, `POST`, `PUT`, `DELETE` 等
- **URL**：请求的资源地址
- **请求头**：附加信息，如用户代理、认证信息等
- **请求体**：POST 或 PUT 请求中携带的数据

**HTTP 响应的关键组成部分**：
- **状态码**：表示请求结果，如 `200 OK`, `404 Not Found`, `500 Internal Server Error`
- **响应头**：附加信息，如内容类型、服务器信息等
- **响应体**：返回的数据，如 HTML、JSON、XML 等

### 2. 用户代理（User-Agent）

项目中使用用户代理来标识客户端身份：

```python
# 增强版中的用户代理设置
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...'
}
response = requests.get(url, headers=headers, timeout=10)
```

**为什么需要用户代理？**
- **身份识别**：向服务器表明客户端类型
- **反爬虫策略**：模拟浏览器行为，避免被某些网站拒绝
- **内容协商**：服务器可能根据用户代理返回不同内容

## 🚀 requests 库深度解析

`requests` 是 Python 中最流行的 HTTP 请求库，它简化了网络请求的复杂性。

### 1. 发送 GET 请求

```python
# rss_reader.py 第 60 行
response = requests.get(url, timeout=10)
```

**GET 请求的完整示例**：

```python
import requests

# 基础 GET 请求
response = requests.get('https://api.github.com')

# 带参数的 GET 请求
params = {'q': 'python', 'sort': 'stars'}
response = requests.get('https://api.github.com/search/repositories', params=params)

# 带请求头的 GET 请求
headers = {
    'Accept': 'application/vnd.github.v3+json',
    'User-Agent': 'My-App/1.0'
}
response = requests.get('https://api.github.com', headers=headers)

# 带超时的 GET 请求
response = requests.get('https://api.github.com', timeout=5)  # 5 秒超时

# 检查响应
if response.status_code == 200:
    print("请求成功")
    print("响应内容:", response.json())  # 解析 JSON 响应
else:
    print(f"请求失败，状态码: {response.status_code}")
```

### 2. 响应对象（Response）

`requests.get()` 返回一个 `Response` 对象，包含了所有响应信息。

```python
# 项目中对响应对象的处理

# 检查状态码
response.raise_for_status()  # 如果状态码不是 2xx，则抛出异常

# 获取响应内容
content = response.content  # 字节流
text = response.text      # 解码后的字符串
json_data = response.json() # 解析 JSON

# 获取状态码
status_code = response.status_code

# 获取响应头
headers = response.headers
print(f"内容类型: {headers.get('Content-Type')}")
```

### 3. 会话对象（Session）

如果你需要与同一个网站进行多次请求，使用 `Session` 对象可以提高性能。

```python
import requests

# 创建会话对象
session = requests.Session()

# 设置会话的默认请求头
session.headers.update({
    'User-Agent': 'My-App/1.0'
})

# 使用会话发送请求
response1 = session.get('https://api.github.com/users/python')
response2 = session.get('https://api.github.com/users/google')

# 优点：
# 1. 保持连接（Keep-Alive）：多次请求复用 TCP 连接
# 2. 自动处理 Cookie：在多次请求中保持会话状态
# 3. 共享配置：如请求头、认证信息等
```

## 🛡️ 网络请求异常处理

RSS 项目中对网络请求异常的处理：

```python
# rss_reader.py 第 79-81 行
except requests.exceptions.RequestException as e:
    print(f"❌ 网络请求失败: {e}")
    return False
```

**requests 库的异常层次结构**：

```
requests.exceptions.RequestException  # 所有异常的基类
    |
    +-- requests.exceptions.ConnectionError
    |   |
    |   +-- requests.exceptions.ProxyError
    |   +-- requests.exceptions.SSLError
    |
    +-- requests.exceptions.HTTPError
    |
    +-- requests.exceptions.Timeout
    |   |
    |   +-- requests.exceptions.ConnectTimeout
    |   +-- requests.exceptions.ReadTimeout
    |
    +-- requests.exceptions.URLRequired
    |
    +-- requests.exceptions.TooManyRedirects
```

**完善的异常处理策略**：

```python
def safe_get(url, timeout=10):
    """安全的 GET 请求函数"""
    try:
        response = requests.get(url, timeout=timeout)
        response.raise_for_status()  # 检查 HTTP 错误
        return response
    except requests.exceptions.Timeout:
        print(f"❌ 请求超时: {url}")
    except requests.exceptions.HTTPError as e:
        print(f"❌ HTTP 错误 ({e.response.status_code}): {url}")
    except requests.exceptions.ConnectionError:
        print(f"❌ 网络连接错误: {url}")
    except requests.exceptions.RequestException as e:
        print(f"❌ 请求异常: {url} - {e}")
    
    return None
```

### 重试机制

可以使用 `urllib3` 的重试功能或手动实现重试：

```python
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import time

# 方案1：使用 requests 的重试适配器
def requests_with_retry(retries=3, backoff_factor=0.5, 
                        status_forcelist=(500, 502, 503, 504)):
    """创建带重试功能的 requests 会话"""
    session = requests.Session()
    retry = Retry(
        total=retries,              # 总重试次数
        read=retries,               # 读取重试次数
        connect=retries,            # 连接重试次数
        backoff_factor=backoff_factor, # 重试间隔因子
        status_forcelist=status_forcelist, # 需要重试的状态码
        method_whitelist=frozenset(['GET', 'POST']) # 重试的请求方法
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session

# 使用示例
session = requests_with_retry()
session.get('https://httpbin.org/status/503') # 会自动重试

# 方案2：手动实现重试
def manual_retry_get(url, retries=3, delay=1):
    """手动实现重试"""
    for i in range(retries):
        try:
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                return response
            print(f"尝试 {i+1}/{retries}: 状态码 {response.status_code}")
        except requests.exceptions.RequestException as e:
            print(f"尝试 {i+1}/{retries}: 异常 {e}")
        
        time.sleep(delay) # 等待一段时间再重试
    
    print("❌ 所有重试都失败了")
    return None
```

## 📰 feedparser 库深度解析

`feedparser` 是一个强大的库，可以解析多种格式的订阅源。

### 1. 解析 RSS/Atom 内容

项目中的解析代码：

```python
# rss_reader.py 第 64 行
feed = feedparser.parse(response.content)

# 第 117 行
feed = feedparser.parse(response.content)
```

`feedparser.parse` 可以接受多种输入：
- URL 字符串
- 文件路径
- XML 字符串或字节流

### 2. 解析结果的数据结构

`feedparser.parse` 返回一个字典式对象，包含以下主要部分：

```python
feed = feedparser.parse(rss_content)

# 1. 订阅源元数据 (feed.feed)
feed_info = feed.feed
print(f"标题: {feed_info.get('title', '未知')}")
print(f"链接: {feed_info.get('link', '未知')}")
print(f"描述: {feed_info.get('subtitle', '未知')}")

# 2. 文章列表 (feed.entries)
articles = feed.entries

# 遍历文章
for entry in articles:
    print(f"  文章标题: {entry.title}")
    print(f"  文章链接: {entry.link}")
    print(f"  发布日期: {entry.get('published', '未知')}")
    print(f"  摘要: {entry.get('summary', '未知')}")
    print("---")

# 3. 错误处理信息
if feed.bozo:
    print("⚠️  解析时出现问题")
    print(f"错误原因: {feed.bozo_exception}")
```

### 3. 数据规范化

`feedparser` 的一大优势是它将不同格式的订阅源解析成统一的数据结构。

```python
# RSS 2.0 字段
# - item.title
# - item.link
# - item.description
# - item.pubDate

# Atom 字段
# - entry.title
# - entry.link (href)
# - entry.summary
# - entry.updated

# feedparser 统一后的字段
# - entry.title
# - entry.link
# - entry.summary
# - entry.published

# 项目中的数据提取代码
article = {
    'title': entry.get('title', '无标题'),
    'link': entry.get('link', ''),
    'summary': entry.get('summary', entry.get('description', '无摘要')),
    'published': entry.get('published', '未知日期')
}
```

### 4. 高级用法

```python
import feedparser

# 1. 设置请求头（避免被拒绝）
headers = {
    'User-Agent': 'Mozilla/5.0 ...'
}
feed = feedparser.parse('https://example.com/rss', 
                       request_headers=headers)

# 2. 处理 ETag 和 Last-Modified（节省带宽）
etag = feed.get('etag')
modified = feed.get('modified')

# 下次请求时带上
feed_next = feedparser.parse('https://example.com/rss', 
                             etag=etag, 
                             modified=modified)

if feed_next.status == 304:  # Not Modified
    print("✅ 订阅源内容未更新")
else:
    print("🔄 订阅源内容已更新")

# 3. 自定义内容处理器
def my_content_processor(data):
    """自定义内容处理器"""
    # 在这里可以对 HTML 内容进行清理或转换
    return data

feedparser.register_content_handler('application/my-format', 
                                    my_content_processor)
```

## 📦 依赖管理与虚拟环境

### 1. 为什么需要虚拟环境？

虚拟环境可以为每个项目创建独立的 Python 环境，解决以下问题：
- **依赖冲突**：项目 A 需要 `requests==2.20.0`，项目 B 需要 `requests==2.25.0`
- **环境污染**：全局安装大量库，导致环境混乱
- **版本锁定**：确保项目在不同机器上使用相同的依赖版本

### 2. 创建和使用虚拟环境

```bash
# 1. 创建虚拟环境
python3 -m venv venv  # venv 是虚拟环境目录

# 2. 激活虚拟环境
# macOS/Linux
source venv/bin/activate

# Windows (Command Prompt)
venv\Scripts\activate.bat

# Windows (PowerShell)
venv\Scripts\Activate.ps1

# 激活后，命令行提示符会显示 (venv)

# 3. 安装依赖
pip install -r requirements.txt

# 4. 运行程序
python rss_reader.py

# 5. 退出虚拟环境
deactivate
```

### 3. `requirements.txt` 文件

项目中使用 `requirements.txt` 来管理依赖。

```
# requirements.txt
requests==2.25.1
feedparser==6.0.2
python-dateutil==2.8.2  # 增强版可能需要
beautifulsoup4==4.9.3   # HTML 清理
```

**生成和更新 `requirements.txt`**：

```bash
# 1. 生成依赖文件（推荐）
pip freeze > requirements.txt

# 2. 安装依赖
pip install -r requirements.txt

# 3. 更新依赖
pip install --upgrade requests
pip freeze > requirements.txt
```

## 🔧 实际应用案例

### 增强的 RSS 获取器

结合以上概念，创建一个更强大的 RSS 获取器：

```python
import requests
import feedparser
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

class AdvancedFeedFetcher:
    """增强的 RSS 获取器"""
    
    def __init__(self, retries=3, backoff_factor=0.5):
        self.session = self._create_session(retries, backoff_factor)
    
    def _create_session(self, retries, backoff_factor):
        """创建带重试和用户代理的会话"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...'
        })
        
        retry = Retry(
            total=retries,
            read=retries,
            connect=retries,
            backoff_factor=backoff_factor,
            status_forcelist=(500, 502, 503, 504)
        )
        adapter = HTTPAdapter(max_retries=retry)
        session.mount('http://', adapter)
        session.mount('https://', adapter)
        return session
    
    def fetch_feed(self, url: str, etag: str = None, modified: str = None) -> dict:
        """获取并解析 RSS 源"""
        try:
            # 使用 feedparser 的请求功能
            feed = feedparser.parse(url, 
                                   request_headers=self.session.headers, 
                                   etag=etag, 
                                   modified=modified)
            
            if feed.bozo:
                print(f"⚠️  解析时出现问题: {feed.bozo_exception}")
            
            return {
                'feed': feed,
                'status': feed.status,
                'etag': feed.get('etag'),
                'modified': feed.get('modified')
            }
            
        except Exception as e:
            print(f"❌ 获取 RSS 源失败: {e}")
            return None

# 使用示例
fetcher = AdvancedFeedFetcher()

# 第一次获取
result1 = fetcher.fetch_feed('https://blog.python.org/feeds/posts/default?alt=rss')

if result1:
    print(f"获取到 {len(result1['feed'].entries)} 篇文章")
    
    # 第二次获取（带 ETag 和 Last-Modified）
    result2 = fetcher.fetch_feed('https://blog.python.org/feeds/posts/default?alt=rss', 
                                 etag=result1['etag'], 
                                 modified=result1['modified'])
    
    if result2 and result2['status'] == 304:
        print("✅ 订阅源内容未更新")
    else:
        print("🔄 订阅源内容已更新")
```

## 🎯 学习检查点

完成本章学习后，你应该能够：

### ✅ 基础概念检查
- [ ] 理解 HTTP 请求和响应的基本原理
- [ ] 熟练使用 `requests` 库发送 GET 请求
- [ ] 掌握 `feedparser` 库的解析机制
- [ ] 正确处理网络请求中的常见异常
- [ ] 理解虚拟环境的重要性和使用方法
- [ ] 熟练管理 `requirements.txt` 文件
- [ ] 了解会话对象和重试机制的应用

### 🧪 实践练习建议

1. **增强 RSS 项目的网络请求**：
   - 实现请求重试机制
   - 添加 ETag 和 Last-Modified 支持
   - 实现异步请求，提高性能

2. **创建独立的网络模块**：
   - 将网络请求相关代码封装到一个独立的模块
   - 提供统一的网络请求接口

3. **扩展 feedparser 的功能**：
   - 自定义内容处理器，清理 HTML 内容
   - 添加对其他订阅源格式的支持（如 JSON Feed）

4. **完善错误处理**：
   - 为不同类型的网络错误提供更具体的提示
   - 实现网络连接状态检测

5. **使用虚拟环境管理项目**：
   - 为 RSS 项目创建一个独立的虚拟环境
   - 锁定依赖版本，确保可复现性

## 🚀 下一步

现在你已经掌握了网络编程和第三方库的使用，接下来将学习**用户交互与界面设计**，了解如何构建用户友好的命令行应用。

请继续阅读：`07_用户交互与界面设计.md`

---

*与外部服务交互是现代软件开发的重要组成部分，熟练掌握第三方库的使用是提高开发效率的关键！* 🌐🛠️
