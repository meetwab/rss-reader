# ç½‘ç»œç¼–ç¨‹ä¸ç¬¬ä¸‰æ–¹åº“ä½¿ç”¨

## ğŸ“š æœ¬æ–‡æ¡£ç›®æ ‡

æ·±å…¥å­¦ä¹  RSS é¡¹ç›®ä¸­çš„ç½‘ç»œç¼–ç¨‹å’Œç¬¬ä¸‰æ–¹åº“ä½¿ç”¨ï¼Œç†è§£å¦‚ä½•ä¸å¤–éƒ¨æœåŠ¡äº¤äº’å¹¶å¤„ç†æ•°æ®ã€‚é€šè¿‡æœ¬æ–‡æ¡£ï¼Œä½ å°†ï¼š

- æŒæ¡ HTTP è¯·æ±‚çš„åŸºæœ¬åŸç†
- ç†Ÿç»ƒä½¿ç”¨ `requests` åº“å‘é€ç½‘ç»œè¯·æ±‚
- ç†è§£ `feedparser` åº“çš„ RSS/Atom è§£ææœºåˆ¶
- å­¦ä¹ å¤„ç†ç½‘ç»œè¯·æ±‚ä¸­çš„å¼‚å¸¸å’Œé”™è¯¯
- æŒæ¡ä¾èµ–ç®¡ç†å’Œè™šæ‹Ÿç¯å¢ƒçš„æœ€ä½³å®è·µ

## ğŸŒ HTTP è¯·æ±‚åŸºç¡€

### 1. HTTP è¯·æ±‚ä¸å“åº”

åœ¨ RSS é¡¹ç›®ä¸­ï¼Œç¨‹åºé€šè¿‡å‘é€ HTTP GET è¯·æ±‚åˆ° RSS æºçš„ URL æ¥è·å–æ•°æ®ã€‚

**HTTP è¯·æ±‚çš„å…³é”®ç»„æˆéƒ¨åˆ†**ï¼š
- **è¯·æ±‚æ–¹æ³•**ï¼š`GET`, `POST`, `PUT`, `DELETE` ç­‰
- **URL**ï¼šè¯·æ±‚çš„èµ„æºåœ°å€
- **è¯·æ±‚å¤´**ï¼šé™„åŠ ä¿¡æ¯ï¼Œå¦‚ç”¨æˆ·ä»£ç†ã€è®¤è¯ä¿¡æ¯ç­‰
- **è¯·æ±‚ä½“**ï¼šPOST æˆ– PUT è¯·æ±‚ä¸­æºå¸¦çš„æ•°æ®

**HTTP å“åº”çš„å…³é”®ç»„æˆéƒ¨åˆ†**ï¼š
- **çŠ¶æ€ç **ï¼šè¡¨ç¤ºè¯·æ±‚ç»“æœï¼Œå¦‚ `200 OK`, `404 Not Found`, `500 Internal Server Error`
- **å“åº”å¤´**ï¼šé™„åŠ ä¿¡æ¯ï¼Œå¦‚å†…å®¹ç±»å‹ã€æœåŠ¡å™¨ä¿¡æ¯ç­‰
- **å“åº”ä½“**ï¼šè¿”å›çš„æ•°æ®ï¼Œå¦‚ HTMLã€JSONã€XML ç­‰

### 2. ç”¨æˆ·ä»£ç†ï¼ˆUser-Agentï¼‰

é¡¹ç›®ä¸­ä½¿ç”¨ç”¨æˆ·ä»£ç†æ¥æ ‡è¯†å®¢æˆ·ç«¯èº«ä»½ï¼š

```python
# å¢å¼ºç‰ˆä¸­çš„ç”¨æˆ·ä»£ç†è®¾ç½®
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...'
}
response = requests.get(url, headers=headers, timeout=10)
```

**ä¸ºä»€ä¹ˆéœ€è¦ç”¨æˆ·ä»£ç†ï¼Ÿ**
- **èº«ä»½è¯†åˆ«**ï¼šå‘æœåŠ¡å™¨è¡¨æ˜å®¢æˆ·ç«¯ç±»å‹
- **åçˆ¬è™«ç­–ç•¥**ï¼šæ¨¡æ‹Ÿæµè§ˆå™¨è¡Œä¸ºï¼Œé¿å…è¢«æŸäº›ç½‘ç«™æ‹’ç»
- **å†…å®¹åå•†**ï¼šæœåŠ¡å™¨å¯èƒ½æ ¹æ®ç”¨æˆ·ä»£ç†è¿”å›ä¸åŒå†…å®¹

## ğŸš€ requests åº“æ·±åº¦è§£æ

`requests` æ˜¯ Python ä¸­æœ€æµè¡Œçš„ HTTP è¯·æ±‚åº“ï¼Œå®ƒç®€åŒ–äº†ç½‘ç»œè¯·æ±‚çš„å¤æ‚æ€§ã€‚

### 1. å‘é€ GET è¯·æ±‚

```python
# rss_reader.py ç¬¬ 60 è¡Œ
response = requests.get(url, timeout=10)
```

**GET è¯·æ±‚çš„å®Œæ•´ç¤ºä¾‹**ï¼š

```python
import requests

# åŸºç¡€ GET è¯·æ±‚
response = requests.get('https://api.github.com')

# å¸¦å‚æ•°çš„ GET è¯·æ±‚
params = {'q': 'python', 'sort': 'stars'}
response = requests.get('https://api.github.com/search/repositories', params=params)

# å¸¦è¯·æ±‚å¤´çš„ GET è¯·æ±‚
headers = {
    'Accept': 'application/vnd.github.v3+json',
    'User-Agent': 'My-App/1.0'
}
response = requests.get('https://api.github.com', headers=headers)

# å¸¦è¶…æ—¶çš„ GET è¯·æ±‚
response = requests.get('https://api.github.com', timeout=5)  # 5 ç§’è¶…æ—¶

# æ£€æŸ¥å“åº”
if response.status_code == 200:
    print("è¯·æ±‚æˆåŠŸ")
    print("å“åº”å†…å®¹:", response.json())  # è§£æ JSON å“åº”
else:
    print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
```

### 2. å“åº”å¯¹è±¡ï¼ˆResponseï¼‰

`requests.get()` è¿”å›ä¸€ä¸ª `Response` å¯¹è±¡ï¼ŒåŒ…å«äº†æ‰€æœ‰å“åº”ä¿¡æ¯ã€‚

```python
# é¡¹ç›®ä¸­å¯¹å“åº”å¯¹è±¡çš„å¤„ç†

# æ£€æŸ¥çŠ¶æ€ç 
response.raise_for_status()  # å¦‚æœçŠ¶æ€ç ä¸æ˜¯ 2xxï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸

# è·å–å“åº”å†…å®¹
content = response.content  # å­—èŠ‚æµ
text = response.text      # è§£ç åçš„å­—ç¬¦ä¸²
json_data = response.json() # è§£æ JSON

# è·å–çŠ¶æ€ç 
status_code = response.status_code

# è·å–å“åº”å¤´
headers = response.headers
print(f"å†…å®¹ç±»å‹: {headers.get('Content-Type')}")
```

### 3. ä¼šè¯å¯¹è±¡ï¼ˆSessionï¼‰

å¦‚æœä½ éœ€è¦ä¸åŒä¸€ä¸ªç½‘ç«™è¿›è¡Œå¤šæ¬¡è¯·æ±‚ï¼Œä½¿ç”¨ `Session` å¯¹è±¡å¯ä»¥æé«˜æ€§èƒ½ã€‚

```python
import requests

# åˆ›å»ºä¼šè¯å¯¹è±¡
session = requests.Session()

# è®¾ç½®ä¼šè¯çš„é»˜è®¤è¯·æ±‚å¤´
session.headers.update({
    'User-Agent': 'My-App/1.0'
})

# ä½¿ç”¨ä¼šè¯å‘é€è¯·æ±‚
response1 = session.get('https://api.github.com/users/python')
response2 = session.get('https://api.github.com/users/google')

# ä¼˜ç‚¹ï¼š
# 1. ä¿æŒè¿æ¥ï¼ˆKeep-Aliveï¼‰ï¼šå¤šæ¬¡è¯·æ±‚å¤ç”¨ TCP è¿æ¥
# 2. è‡ªåŠ¨å¤„ç† Cookieï¼šåœ¨å¤šæ¬¡è¯·æ±‚ä¸­ä¿æŒä¼šè¯çŠ¶æ€
# 3. å…±äº«é…ç½®ï¼šå¦‚è¯·æ±‚å¤´ã€è®¤è¯ä¿¡æ¯ç­‰
```

## ğŸ›¡ï¸ ç½‘ç»œè¯·æ±‚å¼‚å¸¸å¤„ç†

RSS é¡¹ç›®ä¸­å¯¹ç½‘ç»œè¯·æ±‚å¼‚å¸¸çš„å¤„ç†ï¼š

```python
# rss_reader.py ç¬¬ 79-81 è¡Œ
except requests.exceptions.RequestException as e:
    print(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
    return False
```

**requests åº“çš„å¼‚å¸¸å±‚æ¬¡ç»“æ„**ï¼š

```
requests.exceptions.RequestException  # æ‰€æœ‰å¼‚å¸¸çš„åŸºç±»
    |
    +-- requests.exceptions.ConnectionError
    |   |
    |   +-- requests.exceptions.ProxyError
    |   +-- requests.exceptions.SSLError
    |
    +-- requests.exceptions.HTTPError
    |
    +-- requests.exceptions.Timeout
    |   |
    |   +-- requests.exceptions.ConnectTimeout
    |   +-- requests.exceptions.ReadTimeout
    |
    +-- requests.exceptions.URLRequired
    |
    +-- requests.exceptions.TooManyRedirects
```

**å®Œå–„çš„å¼‚å¸¸å¤„ç†ç­–ç•¥**ï¼š

```python
def safe_get(url, timeout=10):
    """å®‰å…¨çš„ GET è¯·æ±‚å‡½æ•°"""
    try:
        response = requests.get(url, timeout=timeout)
        response.raise_for_status()  # æ£€æŸ¥ HTTP é”™è¯¯
        return response
    except requests.exceptions.Timeout:
        print(f"âŒ è¯·æ±‚è¶…æ—¶: {url}")
    except requests.exceptions.HTTPError as e:
        print(f"âŒ HTTP é”™è¯¯ ({e.response.status_code}): {url}")
    except requests.exceptions.ConnectionError:
        print(f"âŒ ç½‘ç»œè¿æ¥é”™è¯¯: {url}")
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚å¼‚å¸¸: {url} - {e}")
    
    return None
```

### é‡è¯•æœºåˆ¶

å¯ä»¥ä½¿ç”¨ `urllib3` çš„é‡è¯•åŠŸèƒ½æˆ–æ‰‹åŠ¨å®ç°é‡è¯•ï¼š

```python
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import time

# æ–¹æ¡ˆ1ï¼šä½¿ç”¨ requests çš„é‡è¯•é€‚é…å™¨
def requests_with_retry(retries=3, backoff_factor=0.5, 
                        status_forcelist=(500, 502, 503, 504)):
    """åˆ›å»ºå¸¦é‡è¯•åŠŸèƒ½çš„ requests ä¼šè¯"""
    session = requests.Session()
    retry = Retry(
        total=retries,              # æ€»é‡è¯•æ¬¡æ•°
        read=retries,               # è¯»å–é‡è¯•æ¬¡æ•°
        connect=retries,            # è¿æ¥é‡è¯•æ¬¡æ•°
        backoff_factor=backoff_factor, # é‡è¯•é—´éš”å› å­
        status_forcelist=status_forcelist, # éœ€è¦é‡è¯•çš„çŠ¶æ€ç 
        method_whitelist=frozenset(['GET', 'POST']) # é‡è¯•çš„è¯·æ±‚æ–¹æ³•
    )
    adapter = HTTPAdapter(max_retries=retry)
    session.mount('http://', adapter)
    session.mount('https://', adapter)
    return session

# ä½¿ç”¨ç¤ºä¾‹
session = requests_with_retry()
session.get('https://httpbin.org/status/503') # ä¼šè‡ªåŠ¨é‡è¯•

# æ–¹æ¡ˆ2ï¼šæ‰‹åŠ¨å®ç°é‡è¯•
def manual_retry_get(url, retries=3, delay=1):
    """æ‰‹åŠ¨å®ç°é‡è¯•"""
    for i in range(retries):
        try:
            response = requests.get(url, timeout=5)
            if response.status_code == 200:
                return response
            print(f"å°è¯• {i+1}/{retries}: çŠ¶æ€ç  {response.status_code}")
        except requests.exceptions.RequestException as e:
            print(f"å°è¯• {i+1}/{retries}: å¼‚å¸¸ {e}")
        
        time.sleep(delay) # ç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯•
    
    print("âŒ æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")
    return None
```

## ğŸ“° feedparser åº“æ·±åº¦è§£æ

`feedparser` æ˜¯ä¸€ä¸ªå¼ºå¤§çš„åº“ï¼Œå¯ä»¥è§£æå¤šç§æ ¼å¼çš„è®¢é˜…æºã€‚

### 1. è§£æ RSS/Atom å†…å®¹

é¡¹ç›®ä¸­çš„è§£æä»£ç ï¼š

```python
# rss_reader.py ç¬¬ 64 è¡Œ
feed = feedparser.parse(response.content)

# ç¬¬ 117 è¡Œ
feed = feedparser.parse(response.content)
```

`feedparser.parse` å¯ä»¥æ¥å—å¤šç§è¾“å…¥ï¼š
- URL å­—ç¬¦ä¸²
- æ–‡ä»¶è·¯å¾„
- XML å­—ç¬¦ä¸²æˆ–å­—èŠ‚æµ

### 2. è§£æç»“æœçš„æ•°æ®ç»“æ„

`feedparser.parse` è¿”å›ä¸€ä¸ªå­—å…¸å¼å¯¹è±¡ï¼ŒåŒ…å«ä»¥ä¸‹ä¸»è¦éƒ¨åˆ†ï¼š

```python
feed = feedparser.parse(rss_content)

# 1. è®¢é˜…æºå…ƒæ•°æ® (feed.feed)
feed_info = feed.feed
print(f"æ ‡é¢˜: {feed_info.get('title', 'æœªçŸ¥')}")
print(f"é“¾æ¥: {feed_info.get('link', 'æœªçŸ¥')}")
print(f"æè¿°: {feed_info.get('subtitle', 'æœªçŸ¥')}")

# 2. æ–‡ç« åˆ—è¡¨ (feed.entries)
articles = feed.entries

# éå†æ–‡ç« 
for entry in articles:
    print(f"  æ–‡ç« æ ‡é¢˜: {entry.title}")
    print(f"  æ–‡ç« é“¾æ¥: {entry.link}")
    print(f"  å‘å¸ƒæ—¥æœŸ: {entry.get('published', 'æœªçŸ¥')}")
    print(f"  æ‘˜è¦: {entry.get('summary', 'æœªçŸ¥')}")
    print("---")

# 3. é”™è¯¯å¤„ç†ä¿¡æ¯
if feed.bozo:
    print("âš ï¸  è§£ææ—¶å‡ºç°é—®é¢˜")
    print(f"é”™è¯¯åŸå› : {feed.bozo_exception}")
```

### 3. æ•°æ®è§„èŒƒåŒ–

`feedparser` çš„ä¸€å¤§ä¼˜åŠ¿æ˜¯å®ƒå°†ä¸åŒæ ¼å¼çš„è®¢é˜…æºè§£ææˆç»Ÿä¸€çš„æ•°æ®ç»“æ„ã€‚

```python
# RSS 2.0 å­—æ®µ
# - item.title
# - item.link
# - item.description
# - item.pubDate

# Atom å­—æ®µ
# - entry.title
# - entry.link (href)
# - entry.summary
# - entry.updated

# feedparser ç»Ÿä¸€åçš„å­—æ®µ
# - entry.title
# - entry.link
# - entry.summary
# - entry.published

# é¡¹ç›®ä¸­çš„æ•°æ®æå–ä»£ç 
article = {
    'title': entry.get('title', 'æ— æ ‡é¢˜'),
    'link': entry.get('link', ''),
    'summary': entry.get('summary', entry.get('description', 'æ— æ‘˜è¦')),
    'published': entry.get('published', 'æœªçŸ¥æ—¥æœŸ')
}
```

### 4. é«˜çº§ç”¨æ³•

```python
import feedparser

# 1. è®¾ç½®è¯·æ±‚å¤´ï¼ˆé¿å…è¢«æ‹’ç»ï¼‰
headers = {
    'User-Agent': 'Mozilla/5.0 ...'
}
feed = feedparser.parse('https://example.com/rss', 
                       request_headers=headers)

# 2. å¤„ç† ETag å’Œ Last-Modifiedï¼ˆèŠ‚çœå¸¦å®½ï¼‰
etag = feed.get('etag')
modified = feed.get('modified')

# ä¸‹æ¬¡è¯·æ±‚æ—¶å¸¦ä¸Š
feed_next = feedparser.parse('https://example.com/rss', 
                             etag=etag, 
                             modified=modified)

if feed_next.status == 304:  # Not Modified
    print("âœ… è®¢é˜…æºå†…å®¹æœªæ›´æ–°")
else:
    print("ğŸ”„ è®¢é˜…æºå†…å®¹å·²æ›´æ–°")

# 3. è‡ªå®šä¹‰å†…å®¹å¤„ç†å™¨
def my_content_processor(data):
    """è‡ªå®šä¹‰å†…å®¹å¤„ç†å™¨"""
    # åœ¨è¿™é‡Œå¯ä»¥å¯¹ HTML å†…å®¹è¿›è¡Œæ¸…ç†æˆ–è½¬æ¢
    return data

feedparser.register_content_handler('application/my-format', 
                                    my_content_processor)
```

## ğŸ“¦ ä¾èµ–ç®¡ç†ä¸è™šæ‹Ÿç¯å¢ƒ

### 1. ä¸ºä»€ä¹ˆéœ€è¦è™šæ‹Ÿç¯å¢ƒï¼Ÿ

è™šæ‹Ÿç¯å¢ƒå¯ä»¥ä¸ºæ¯ä¸ªé¡¹ç›®åˆ›å»ºç‹¬ç«‹çš„ Python ç¯å¢ƒï¼Œè§£å†³ä»¥ä¸‹é—®é¢˜ï¼š
- **ä¾èµ–å†²çª**ï¼šé¡¹ç›® A éœ€è¦ `requests==2.20.0`ï¼Œé¡¹ç›® B éœ€è¦ `requests==2.25.0`
- **ç¯å¢ƒæ±¡æŸ“**ï¼šå…¨å±€å®‰è£…å¤§é‡åº“ï¼Œå¯¼è‡´ç¯å¢ƒæ··ä¹±
- **ç‰ˆæœ¬é”å®š**ï¼šç¡®ä¿é¡¹ç›®åœ¨ä¸åŒæœºå™¨ä¸Šä½¿ç”¨ç›¸åŒçš„ä¾èµ–ç‰ˆæœ¬

### 2. åˆ›å»ºå’Œä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ

```bash
# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv  # venv æ˜¯è™šæ‹Ÿç¯å¢ƒç›®å½•

# 2. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# macOS/Linux
source venv/bin/activate

# Windows (Command Prompt)
venv\Scripts\activate.bat

# Windows (PowerShell)
venv\Scripts\Activate.ps1

# æ¿€æ´»åï¼Œå‘½ä»¤è¡Œæç¤ºç¬¦ä¼šæ˜¾ç¤º (venv)

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. è¿è¡Œç¨‹åº
python rss_reader.py

# 5. é€€å‡ºè™šæ‹Ÿç¯å¢ƒ
deactivate
```

### 3. `requirements.txt` æ–‡ä»¶

é¡¹ç›®ä¸­ä½¿ç”¨ `requirements.txt` æ¥ç®¡ç†ä¾èµ–ã€‚

```
# requirements.txt
requests==2.25.1
feedparser==6.0.2
python-dateutil==2.8.2  # å¢å¼ºç‰ˆå¯èƒ½éœ€è¦
beautifulsoup4==4.9.3   # HTML æ¸…ç†
```

**ç”Ÿæˆå’Œæ›´æ–° `requirements.txt`**ï¼š

```bash
# 1. ç”Ÿæˆä¾èµ–æ–‡ä»¶ï¼ˆæ¨èï¼‰
pip freeze > requirements.txt

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. æ›´æ–°ä¾èµ–
pip install --upgrade requests
pip freeze > requirements.txt
```

## ğŸ”§ å®é™…åº”ç”¨æ¡ˆä¾‹

### å¢å¼ºçš„ RSS è·å–å™¨

ç»“åˆä»¥ä¸Šæ¦‚å¿µï¼Œåˆ›å»ºä¸€ä¸ªæ›´å¼ºå¤§çš„ RSS è·å–å™¨ï¼š

```python
import requests
import feedparser
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

class AdvancedFeedFetcher:
    """å¢å¼ºçš„ RSS è·å–å™¨"""
    
    def __init__(self, retries=3, backoff_factor=0.5):
        self.session = self._create_session(retries, backoff_factor)
    
    def _create_session(self, retries, backoff_factor):
        """åˆ›å»ºå¸¦é‡è¯•å’Œç”¨æˆ·ä»£ç†çš„ä¼šè¯"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...'
        })
        
        retry = Retry(
            total=retries,
            read=retries,
            connect=retries,
            backoff_factor=backoff_factor,
            status_forcelist=(500, 502, 503, 504)
        )
        adapter = HTTPAdapter(max_retries=retry)
        session.mount('http://', adapter)
        session.mount('https://', adapter)
        return session
    
    def fetch_feed(self, url: str, etag: str = None, modified: str = None) -> dict:
        """è·å–å¹¶è§£æ RSS æº"""
        try:
            # ä½¿ç”¨ feedparser çš„è¯·æ±‚åŠŸèƒ½
            feed = feedparser.parse(url, 
                                   request_headers=self.session.headers, 
                                   etag=etag, 
                                   modified=modified)
            
            if feed.bozo:
                print(f"âš ï¸  è§£ææ—¶å‡ºç°é—®é¢˜: {feed.bozo_exception}")
            
            return {
                'feed': feed,
                'status': feed.status,
                'etag': feed.get('etag'),
                'modified': feed.get('modified')
            }
            
        except Exception as e:
            print(f"âŒ è·å– RSS æºå¤±è´¥: {e}")
            return None

# ä½¿ç”¨ç¤ºä¾‹
fetcher = AdvancedFeedFetcher()

# ç¬¬ä¸€æ¬¡è·å–
result1 = fetcher.fetch_feed('https://blog.python.org/feeds/posts/default?alt=rss')

if result1:
    print(f"è·å–åˆ° {len(result1['feed'].entries)} ç¯‡æ–‡ç« ")
    
    # ç¬¬äºŒæ¬¡è·å–ï¼ˆå¸¦ ETag å’Œ Last-Modifiedï¼‰
    result2 = fetcher.fetch_feed('https://blog.python.org/feeds/posts/default?alt=rss', 
                                 etag=result1['etag'], 
                                 modified=result1['modified'])
    
    if result2 and result2['status'] == 304:
        print("âœ… è®¢é˜…æºå†…å®¹æœªæ›´æ–°")
    else:
        print("ğŸ”„ è®¢é˜…æºå†…å®¹å·²æ›´æ–°")
```

## ğŸ¯ å­¦ä¹ æ£€æŸ¥ç‚¹

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š

### âœ… åŸºç¡€æ¦‚å¿µæ£€æŸ¥
- [ ] ç†è§£ HTTP è¯·æ±‚å’Œå“åº”çš„åŸºæœ¬åŸç†
- [ ] ç†Ÿç»ƒä½¿ç”¨ `requests` åº“å‘é€ GET è¯·æ±‚
- [ ] æŒæ¡ `feedparser` åº“çš„è§£ææœºåˆ¶
- [ ] æ­£ç¡®å¤„ç†ç½‘ç»œè¯·æ±‚ä¸­çš„å¸¸è§å¼‚å¸¸
- [ ] ç†è§£è™šæ‹Ÿç¯å¢ƒçš„é‡è¦æ€§å’Œä½¿ç”¨æ–¹æ³•
- [ ] ç†Ÿç»ƒç®¡ç† `requirements.txt` æ–‡ä»¶
- [ ] äº†è§£ä¼šè¯å¯¹è±¡å’Œé‡è¯•æœºåˆ¶çš„åº”ç”¨

### ğŸ§ª å®è·µç»ƒä¹ å»ºè®®

1. **å¢å¼º RSS é¡¹ç›®çš„ç½‘ç»œè¯·æ±‚**ï¼š
   - å®ç°è¯·æ±‚é‡è¯•æœºåˆ¶
   - æ·»åŠ  ETag å’Œ Last-Modified æ”¯æŒ
   - å®ç°å¼‚æ­¥è¯·æ±‚ï¼Œæé«˜æ€§èƒ½

2. **åˆ›å»ºç‹¬ç«‹çš„ç½‘ç»œæ¨¡å—**ï¼š
   - å°†ç½‘ç»œè¯·æ±‚ç›¸å…³ä»£ç å°è£…åˆ°ä¸€ä¸ªç‹¬ç«‹çš„æ¨¡å—
   - æä¾›ç»Ÿä¸€çš„ç½‘ç»œè¯·æ±‚æ¥å£

3. **æ‰©å±• feedparser çš„åŠŸèƒ½**ï¼š
   - è‡ªå®šä¹‰å†…å®¹å¤„ç†å™¨ï¼Œæ¸…ç† HTML å†…å®¹
   - æ·»åŠ å¯¹å…¶ä»–è®¢é˜…æºæ ¼å¼çš„æ”¯æŒï¼ˆå¦‚ JSON Feedï¼‰

4. **å®Œå–„é”™è¯¯å¤„ç†**ï¼š
   - ä¸ºä¸åŒç±»å‹çš„ç½‘ç»œé”™è¯¯æä¾›æ›´å…·ä½“çš„æç¤º
   - å®ç°ç½‘ç»œè¿æ¥çŠ¶æ€æ£€æµ‹

5. **ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒç®¡ç†é¡¹ç›®**ï¼š
   - ä¸º RSS é¡¹ç›®åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„è™šæ‹Ÿç¯å¢ƒ
   - é”å®šä¾èµ–ç‰ˆæœ¬ï¼Œç¡®ä¿å¯å¤ç°æ€§

## ğŸš€ ä¸‹ä¸€æ­¥

ç°åœ¨ä½ å·²ç»æŒæ¡äº†ç½‘ç»œç¼–ç¨‹å’Œç¬¬ä¸‰æ–¹åº“çš„ä½¿ç”¨ï¼Œæ¥ä¸‹æ¥å°†å­¦ä¹ **ç”¨æˆ·äº¤äº’ä¸ç•Œé¢è®¾è®¡**ï¼Œäº†è§£å¦‚ä½•æ„å»ºç”¨æˆ·å‹å¥½çš„å‘½ä»¤è¡Œåº”ç”¨ã€‚

è¯·ç»§ç»­é˜…è¯»ï¼š`07_ç”¨æˆ·äº¤äº’ä¸ç•Œé¢è®¾è®¡.md`

---

*ä¸å¤–éƒ¨æœåŠ¡äº¤äº’æ˜¯ç°ä»£è½¯ä»¶å¼€å‘çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œç†Ÿç»ƒæŒæ¡ç¬¬ä¸‰æ–¹åº“çš„ä½¿ç”¨æ˜¯æé«˜å¼€å‘æ•ˆç‡çš„å…³é”®ï¼* ğŸŒğŸ› ï¸
